{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "623cea2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "import numpy as np\n",
    "import scipy.linalg\n",
    "import pickle as pkl\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import scipy.io\n",
    "# from attrdict import AttrDict\n",
    "import argparse\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Gamma\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib.colors\n",
    "from scipy import array, linalg, dot\n",
    "import math\n",
    "from scipy.io import savemat, loadmat\n",
    "# import matplotlib.backends.backend_pdf\n",
    "SMALL_SIZE = 12\n",
    "MEDIUM_SIZE = 14\n",
    "BIGGER_SIZE = 16\n",
    "plt.rc('font',**{'family':'serif','serif':['Times']})\n",
    "plt.rcParams['text.usetex'] = True\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=SMALL_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "# from my_model import mymf\n",
    "import matplotlib as mpl\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.collections import PatchCollection\n",
    "import flopy.utils.binaryfile as bf\n",
    "import shutil\n",
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "import h5py\n",
    "# run installed version of flopy or add local path\n",
    "try:\n",
    "    import flopy\n",
    "except:\n",
    "    fpth = os.path.abspath(os.path.join('..', '..'))\n",
    "    sys.path.append(fpth)\n",
    "    import flopy\n",
    "from flopy.utils.util_array import read1d\n",
    "mpl.rcParams['figure.figsize'] = (8, 8)\n",
    "from TCP3d_model import mymf\n",
    "from para_simu import simu\n",
    "print(sys.version)\n",
    "print('numpy version: {}'.format(np.__version__))\n",
    "print('matplotlib version: {}'.format(mpl.__version__))\n",
    "print('flopy version: {}'.format(flopy.__version__))\n",
    "exe_name_mf = '/Users/zitongzhou/Downloads/pymake/examples/mf2005'\n",
    "exe_name_mt = '/Users/zitongzhou/Downloads/pymake/examples/mt3dms'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b2dea6",
   "metadata": {},
   "source": [
    "# CAAE model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45b379bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reparameterization(mu, logvar):\n",
    "    std = torch.exp(logvar / 2)\n",
    "    eps = torch.randn_like(std)\n",
    "    #randn_like: Returns a tensor with the same size as input that is filled with random numbers from a normal distribution with mean 0 and variance 1.\n",
    "    #return: random gaussian sample from distribution with mu and exp(logvar/2)\n",
    "    return mu + eps*std\n",
    "\n",
    "class DenseResidualBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    The core module of paper: (Residual Dense Network for Image Super-Resolution, CVPR 18)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, filters, res_scale=0.2):\n",
    "        super(DenseResidualBlock, self).__init__()\n",
    "        self.res_scale = res_scale\n",
    "\n",
    "        def block(in_features, non_linearity=True):\n",
    "            layers = [nn.BatchNorm3d(in_features)]\n",
    "            layers += [nn.ReLU(inplace=True)]\n",
    "            layers += [nn.Conv3d(in_features, filters, 3, 1, 1, bias=True)] # does not change state size\n",
    "            return nn.Sequential(*layers)\n",
    "\n",
    "        self.b1 = block(in_features=1 * filters)\n",
    "        self.b2 = block(in_features=2 * filters)\n",
    "        self.b3 = block(in_features=3 * filters)\n",
    "        self.b4 = block(in_features=4 * filters)\n",
    "        self.b5 = block(in_features=5 * filters, non_linearity=False)\n",
    "        self.blocks = [self.b1, self.b2, self.b3, self.b4, self.b5]\n",
    "\n",
    "    def forward(self, x):\n",
    "        inputs = x\n",
    "        for block in self.blocks:\n",
    "            out = block(inputs)\n",
    "            inputs = torch.cat([inputs, out], 1)\n",
    "        return out.mul(self.res_scale) + x\n",
    "\n",
    "\n",
    "class ResidualInResidualDenseBlock(nn.Module):\n",
    "    def __init__(self, filters, res_scale=0.2):\n",
    "        super(ResidualInResidualDenseBlock, self).__init__()\n",
    "        self.res_scale = res_scale\n",
    "        self.dense_blocks = nn.Sequential(\n",
    "            DenseResidualBlock(filters), DenseResidualBlock(filters), DenseResidualBlock(filters)#, DenseResidualBlock(filters)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dense_blocks(x).mul(self.res_scale) + x\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, inchannels=1, outchannels=2, filters=48, num_res_blocks=1):\n",
    "        super(Encoder, self).__init__()\n",
    "        # input size, inchannels x 6 x 41 x 81\n",
    "        self.conv1 = nn.Conv3d(inchannels, filters, kernel_size=3, stride=2, padding=1)\n",
    "        # state size. filters x 3 x 21 x 41\n",
    "        self.res_blocks = nn.Sequential(*[ResidualInResidualDenseBlock(filters) for _ in range(num_res_blocks)])\n",
    "        # state size. filters x 3 x 21 x 41\n",
    "        self.trans = nn.Sequential(\n",
    "            nn.BatchNorm3d(filters),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(filters, filters, kernel_size=3, stride=2, padding=1),\n",
    "        )\n",
    "        # state size. filters x 2 x 11 x 21\n",
    "        self.mu = nn.Conv3d(filters, outchannels, 3, 1, 1, bias=False) #does not change state size.\n",
    "        self.logvar = nn.Conv3d(filters, outchannels, 3, 1, 1, bias=False) #does not change state size.\n",
    "\n",
    "    def forward(self, img):\n",
    "        # img: inchannels x 6 x 41 x 81\n",
    "        out1 = self.conv1(img)        # filters x 3 x 21 x 41\n",
    "        out2 = self.res_blocks(out1)   # filters x 3 x 21 x 41\n",
    "        out3 = self.trans(out2)        # filters x 2 x 11 x 21\n",
    "\n",
    "        mu, logvar = self.mu(out3), self.logvar(out3)\n",
    "        z = reparameterization(mu, logvar) # latent dimension: outchannels x 2 x 11 x 21\n",
    "        return z\n",
    "\n",
    "    def _n_parameters(self):\n",
    "        n_params = 0\n",
    "        for name, param in self.named_parameters():\n",
    "            n_params += param.numel()\n",
    "        return n_params\n",
    "                \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, inchannels=2, outchannels=1, filters=48, num_res_blocks=1,num_upsample=2):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        # First layer. input size, inchannels x 2 x 8 x 16\n",
    "        self.conv1 = nn.Conv3d(inchannels, filters, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # state size. filters x 2 x 8 x 16\n",
    "        # Residual blocks\n",
    "        self.res_block1 = nn.Sequential(*[ResidualInResidualDenseBlock(filters) for _ in range(num_res_blocks+1)])\n",
    "        self.transup1 = nn.Sequential(\n",
    "            nn.BatchNorm3d(filters),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Upsample(size=(4, 21, 41), mode='nearest'),\n",
    "            nn.Conv3d(filters, filters, kernel_size=3, stride=1, padding=1), #does not change state size\n",
    "        )\n",
    "        self.res_block2 = nn.Sequential(*[ResidualInResidualDenseBlock(filters) for _ in range(num_res_blocks)])\n",
    "        self.transup2 = nn.Sequential(\n",
    "            nn.BatchNorm3d(filters),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Upsample(size=(8, 41, 81), mode='nearest'),\n",
    "            nn.Conv3d(filters, outchannels, kernel_size=3, stride=1, padding=(0,1,1)), # reduce the first dimension by 2\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, z):\n",
    "        # x: in_channels x 2 x 8 x 16\n",
    "        out1 = self.conv1(z)          # filters x 2 x 8 x 16\n",
    "        out2 = self.res_block1(out1)   # filters x 2 x 8 x 16\n",
    "        out = torch.add(out1, out2)   # filters x 2 x 8 x 16\n",
    "        out3 = self.transup1(out)      # filters x 4 x 16 x 32\n",
    "        out4 = self.res_block2(out3)   # filters x 4 x 16 x 32\n",
    "\n",
    "        img = self.transup2(out4)     # outchannels x 6 x 32 x 64\n",
    "\n",
    "        return img\n",
    "\n",
    "    def _n_parameters(self):\n",
    "        n_params= 0\n",
    "        for name, param in self.named_parameters():\n",
    "            n_params += param.numel()\n",
    "        return n_params\n",
    "    \n",
    "def to_numpy(input):\n",
    "    if isinstance(input, torch.Tensor):\n",
    "        return input.cpu().detach().numpy()\n",
    "    elif isinstance(input, np.ndarray):\n",
    "        return input\n",
    "    else:\n",
    "        raise TypeError('Unknown type of input, expected torch.Tensor or '\\\n",
    "            'np.ndarray, but got {}'.format(type(input)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7183067",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Load the CAAE model first'''\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "n_train = 23000\n",
    "n_test = 100\n",
    "batch_size = 64\n",
    "n_epochs = 50\n",
    "lr = 0.0002 ## adam learning rate\n",
    "lw = 0.01 ## \"adversarial loss weight\"\n",
    "\n",
    "current_dir = \"/Volumes/GoogleDrive/My Drive/react_inverse/CAAE/\"\n",
    "date = 'experiments/Feb_14_CAAE3D'\n",
    "exp_dir = current_dir + date + \"/N{}_Bts{}_Eps{}_lr{}_lw{}\".\\\n",
    "    format(n_train, batch_size, n_epochs, lr, lw)\n",
    "\n",
    "output_dir = exp_dir + \"/predictions\"\n",
    "model_dir = exp_dir\n",
    "\n",
    "nf, d, h, w = 2, 2, 11, 21\n",
    "\n",
    "# Initialize encoder\n",
    "encoder = Encoder(outchannels=nf)\n",
    "encoder.load_state_dict(torch.load(model_dir + '/AAE_encoder_epoch{}.pth'.format(n_epochs), map_location=torch.device('cpu')))\n",
    "if cuda:\n",
    "    encoder.cuda()\n",
    "\n",
    "encoder.eval()\n",
    "\n",
    "# Initialize decoder\n",
    "decoder = Decoder(inchannels=nf)\n",
    "decoder.load_state_dict(torch.load(model_dir + '/AAE_decoder_epoch{}.pth'.format(n_epochs), map_location=torch.device('cpu')))\n",
    "if cuda:\n",
    "    decoder.cuda()\n",
    "\n",
    "decoder.eval()\n",
    "\n",
    "def plot_3d(data, title='', cut=None):\n",
    "    data = np.transpose(data, (2, 1, 0))\n",
    "    data = np.flip(data, axis=2)\n",
    "    filled = np.ones(data.shape)\n",
    "    if cut is not None:\n",
    "        filled[cut[2]:, :cut[1], (6-cut[0]):] = 0\n",
    "    x, y, z = np.indices(np.array(filled.shape) + 1)\n",
    "    \n",
    "    v1 = np.linspace(np.min(data),np.max(data), 8, endpoint=True)\n",
    "    norm = matplotlib.colors.Normalize(vmin=np.min(data), vmax=np.max(data))\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes(projection='3d')\n",
    "    ax.voxels(x, y, z, filled, facecolors=plt.cm.jet(norm(data)), edgecolors=None)\n",
    "    ax.set_box_aspect([250, 125, 50])\n",
    "    \n",
    "    m = cm.ScalarMappable(cmap=plt.cm.jet, norm=norm)\n",
    "    m.set_array([])\n",
    "    fig.colorbar(m, ax=ax, fraction=0.015, pad=0.04,ticks=v1,)\n",
    "    ax.set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    # ax.set_title(title)\n",
    "    fig.savefig(title+'.pdf')\n",
    "    return fig\n",
    "\n",
    "def simple_plot(c_map, title=''):\n",
    "    nx = 81\n",
    "    ny = 41\n",
    "    Lx = 2500\n",
    "    Ly = 1250\n",
    "\n",
    "    x = np.linspace(0, Lx, nx)\n",
    "    y = np.linspace(0, Ly, ny)\n",
    "    X,Y = np.meshgrid(x, y)\n",
    "    if len(c_map) == 41:\n",
    "        fig, axs = plt.subplots(1,1)\n",
    "    #        axs.set_xlabel('x(m)')\n",
    "    #        axs.set_ylabel('y(m)')\n",
    "        # axs.set_xlim(0,Lx)\n",
    "        # axs.set_ylim(0,Ly)\n",
    "        c01map = axs.imshow(c_map, cmap='jet',\n",
    "                  extent=[x.min(), x.max(), y.min(), y.max()],\n",
    "                  vmin=c_map.min(), vmax = c_map.max(),\n",
    "                  origin='lower')\n",
    "        fig.colorbar(c01map, ax=axs,shrink=0.62)\n",
    "    else:\n",
    "        fig, axs = plt.subplots(len(c_map)//3, 3, figsize=(7, 2.5))\n",
    "        axs = axs.flat\n",
    "        for i, ax in enumerate(axs):\n",
    "            # ax.set_xlim(0,Lx)\n",
    "            # ax.set_ylim(0,Ly)\n",
    "            c01map = ax.imshow(c_map[i], cmap='jet', interpolation='nearest',\n",
    "                      extent=[x.min(), x.max(), y.min(), y.max()],\n",
    "                      vmin=c_map[i].min(), vmax = c_map[i].max(),\n",
    "                      origin='lower')\n",
    "            ax.set_axis_off()\n",
    "            v1 = np.linspace(np.min(c_map[i]),np.max(c_map[i]), 5, endpoint=True)\n",
    "            fig.colorbar(c01map, ax=ax, fraction=0.021, pad=0.04,ticks=v1,)\n",
    "\n",
    "    plt.suptitle(title)\n",
    "    name = title + '.pdf'\n",
    "    plt.tight_layout()\n",
    "#         fig.savefig('images/'+name, format='pdf',bbox_inches='tight')\n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c35b1c",
   "metadata": {},
   "source": [
    "# ESMDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6f298bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ES_MDA(num_ens,m_ens,Z,prod_ens,alpha,CD,corr,numsave=2):\n",
    "    # Z is the obs; prob_ens is the sim_obs; CD is the error\n",
    "    # note that in this func, the shape of the array is (Num_nodes,Num_ens)\n",
    "    varn=1-1/math.pow(10,numsave)\n",
    "    # Initial Variavel \n",
    "    # Forecast step\n",
    "    yf = m_ens.T                      # Non linear forward model, transform to (Num_nodes,Num_ens)\n",
    "    df = prod_ens.T                   # Observation Model, transform to (Num_nodes,Num_ens)\n",
    "    ym = np.array(yf.mean(axis=1))    # Mean of the y_f\n",
    "    dm = np.array(df.mean(axis=1))    # Mean of the d_f\n",
    "    ym=ym.reshape(ym.shape[0],1)    \n",
    "    dm=dm.reshape(dm.shape[0],1)    \n",
    "    dmf = yf - ym\n",
    "    ddf = df - dm\n",
    "    \n",
    "    Cmd_f = (np.dot(dmf,ddf.T))/(num_ens-1);  # The cros-covariance matrix\n",
    "    Cdd_f = (np.dot(ddf,ddf.T))/(num_ens-1);  # The auto covariance of predicted data\n",
    "    \n",
    "    # Perturb the vector of observations\n",
    "    R = linalg.cholesky(CD,lower=True) #Matriz triangular inferior\n",
    "    U = R.T   #Matriz R transposta\n",
    "    p , ww =np.linalg.eig(CD)\n",
    "    \n",
    "    aux = np.repeat(Z,num_ens,axis=1)\n",
    "\n",
    "    mean = 0*(Z.T)\n",
    "\n",
    "    noise=np.random.multivariate_normal(mean[0], np.eye(len(Z)), num_ens).T\n",
    "    d_obs = aux+math.sqrt(alpha)*np.dot(U,noise)  \n",
    "    \n",
    "    # Analysis step\n",
    "    u, s, vh = linalg.svd(Cdd_f+alpha*CD); v = vh.T\n",
    "    diagonal = s\n",
    "    for i in range(len(diagonal)):\n",
    "        if (sum(diagonal[0:i+1]))/(sum(diagonal)) > varn:\n",
    "            diagonal = diagonal[0:i+1]\n",
    "            break\n",
    "    \n",
    "    u=u[:,0:i+1]\n",
    "    v=v[:,0:i+1]\n",
    "    ss = np.diag(diagonal**(-1))\n",
    "    K=np.dot(Cmd_f,(np.dot(np.dot(v,ss),(u.T))))\n",
    "    # Use Kalman covariance\n",
    "    if len(corr)>0:\n",
    "        K = corr*K\n",
    "        \n",
    "    ya = yf + (np.dot(K,(d_obs-df)))\n",
    "    m_ens = ya\n",
    "    return m_ens.T # tranform back to (Num_ens,Num_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9146c07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_obs = np.linspace(5, 35, num=4).astype('int')\n",
    "x_obs = np.linspace(20, 75, num=6).astype('int')\n",
    "sensor = np.zeros((6, 41, 81))\n",
    "for i in range(len(y_obs)):\n",
    "    for j in range(6):\n",
    "        for k in range(len(x_obs)):\n",
    "            sensor[j, int(y_obs[i]), int(x_obs[k])] = 1\n",
    "sensor = sensor>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5b94641",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Volumes/GoogleDrive/My Drive/react_inverse/ILUES/real_hk_data.pkl','rb') as file:\n",
    "    [real_hk, real_conc, real_source_loc, real_source_rate] = pkl.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f80f523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 144)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = []\n",
    "for i in range(len(real_conc)):\n",
    "    obs.append(real_conc[i][sensor])\n",
    "obs = np.stack(obs) #(11, 144)\n",
    "meas_sig = 20*0.025*np.ones(len(obs.reshape(-1)))\n",
    "np.random.seed(888) \n",
    "meas_data = obs + np.random.normal(\n",
    "    np.zeros(len(obs.reshape(-1))), meas_sig\n",
    "    ).reshape(obs.shape)\n",
    "meas_data[meas_data<0] = 0\n",
    "meas_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88861079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1584, 1584)\n"
     ]
    }
   ],
   "source": [
    "ns = 924 + 5 + 2\n",
    "Na = 10\n",
    "Alpha=np.array([Na for _ in range(Na)])\n",
    "meas_data = meas_data.reshape((-1,1))\n",
    "#meas_sig\n",
    "Num_obs = meas_sig.shape[0]\n",
    "R=np.diag(meas_sig.reshape(-1))\n",
    "\n",
    "Num_ens = 960\n",
    "s=np.zeros((Num_ens, ns))\n",
    "# s[:,:,:924, 0] = np.stack([kd_init[:Num_ens,:] for _ in range(20)]) #start from the kd only ensemble\n",
    "np.random.seed(888)\n",
    "s[:, :924] = np.random.randn(Num_ens, 924) #start from random ensemble \n",
    "s[:, 924:929] = np.stack(np.random.uniform(100, 1000, size=(Num_ens, 5)))\n",
    "s[:, 929] = np.random.randint(4, 37, size=Num_ens)\n",
    "s[:, 930] = np.random.randint(4, 20, size=Num_ens)\n",
    "print(R.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9ee4c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE ite_0 :  2.250921271653835\n",
      "RMSE ite_1 :  1.4339657465040547\n",
      "RMSE ite_2 :  1.0218053727349814\n",
      "RMSE ite_3 :  0.6599622283625604\n",
      "RMSE ite_4 :  0.5271580255598823\n",
      "RMSE ite_5 :  0.4964582792383503\n",
      "RMSE ite_6 :  0.48391878706495345\n",
      "RMSE ite_7 :  0.4662654630234263\n",
      "RMSE ite_8 :  0.4582760522013068\n",
      "RMSE ite_9 :  0.45236706819495537\n",
      "RMSE ite_9 :  0.4452537016178549\n"
     ]
    }
   ],
   "source": [
    "problematic_conc = []\n",
    "tic = time.time()\n",
    "for t in range(len(Alpha)):\n",
    "    ## make input files\n",
    "    con_rate = []\n",
    "    kds = []\n",
    "    Sy_id, Sx_id = s[:, 929], s[:, 930]\n",
    "\n",
    "    for sim in range(Num_ens):\n",
    "        kd_latent = s[sim, :924]\n",
    "        kd_latent = Tensor(kd_latent.reshape((-1, nf, d, h, w)))\n",
    "        decoder.eval()\n",
    "        log_K = to_numpy(decoder(kd_latent).reshape(-1, 6, 41, 81))[0]\n",
    "        kds.append(log_K)\n",
    "\n",
    "        welspd = []\n",
    "        source_rate = s[sim, 924:929]\n",
    "        for i in range(5):\n",
    "            welspd.append([3, round(Sy_id[sim]), round(Sx_id[sim]), source_rate[i], -1])\n",
    "        welspd.append([3, round(Sy_id[sim]), round(Sx_id[sim]), 0, -1])\n",
    "        con_rate.append(welspd)\n",
    "\n",
    "    con_rate = np.array(con_rate)\n",
    "\n",
    "    for ndata in range(Num_ens):\n",
    "        hf =  h5py.File('/Volumes/Transcend/Desktop/reactive_inverse/simu_inputs/input_{}.hdf5'.format(ndata), 'w')\n",
    "        hf.create_dataset('kd', data = kds[ndata], dtype ='f', compression = 'gzip')\n",
    "        hf.create_dataset('welspd', data = con_rate[ndata], dtype ='f', compression = 'gzip')\n",
    "        hf.close()\n",
    "    ## run simulations in parallel\n",
    "    cwd = '/Volumes/Transcend/Desktop/reactive_inverse/simu_inputs/'\n",
    "    os.chdir(cwd)\n",
    "    n_pool = 5\n",
    "    pool = Pool(n_pool)\n",
    "    filelist = os.listdir(cwd)\n",
    "    filelist = [file for file in filelist if file.endswith('.hdf5')]\n",
    "    pool.map(simu, filelist)\n",
    "    \n",
    "    sim_obs = np.zeros((Num_ens,Num_obs))\n",
    "    ## read output files\n",
    "    dir = os.listdir('/Volumes/Transcend/Desktop/reactive_inverse/simu_outputs/')\n",
    "    os.chdir('/Volumes/Transcend/Desktop/reactive_inverse/simu_outputs/')\n",
    "    sim_obs = np.zeros((Num_ens,Num_obs))\n",
    "    for n_data in range(Num_ens):\n",
    "        output_name = 'output_{}.hdf5'.format(n_data)\n",
    "        f = h5py.File(output_name, \"r\")\n",
    "        conc = np.array(f['concentration'])\n",
    "        head = np.array(f['head'])\n",
    "        conc[conc<0] = 0\n",
    "        ## there are some very rare cases when the output files are not complete, set these outputs to 0 if it occurs.\n",
    "        if len(conc) != 10 or len(head) != 6:\n",
    "            problematic_conc.append([n_data, t])\n",
    "            conc = np.zeros((10,6,41,81))\n",
    "            head = np.zeros((6,41,81))\n",
    "        f.close()\n",
    "        obs = []\n",
    "        obs.append(head[sensor])\n",
    "        for j in range(len(conc)):\n",
    "            obs.append(conc[j][sensor])\n",
    "        obs = np.stack(obs).reshape(-1)\n",
    "\n",
    "        sim_obs[n_data,:] = obs\n",
    "    \n",
    "    print('RMSE ite_'+str(t)+ ' : ', np.sqrt(np.mean((np.mean(sim_obs,axis=0)-meas_data.flatten())**2))) # not the exact RMSE definition\n",
    "    # mean_error[i, t] = np.sqrt(np.mean((np.mean(sim_obs,axis=0)-meas_data.flatten())**2))\n",
    "    with open('/Volumes/Transcend/Desktop/reactive_inverse/ESMDA/s_{}.pkl'.format(t+1),'wb') as file:\n",
    "        pkl.dump([s, sim_obs], file)\n",
    "    s = ES_MDA(Num_ens, s, meas_data, sim_obs, Alpha[t], R, [], 2)\n",
    "    s[:, 924:929][s[:, 924:929]<0] = 0.\n",
    "    s[:, 924:929][s[:, 924:929]>1000] = 1000.\n",
    "    s[:, 929][s[:, 929]<4] = 4.\n",
    "    s[:, 929][s[:, 929]>37] = 37.\n",
    "    s[:, 930][s[:, 930]<4] = 4.\n",
    "    s[:, 930][s[:, 930]>19] = 19.\n",
    "    \n",
    "## the last ensemble computation\n",
    "con_rate = []\n",
    "kds = []\n",
    "Sy_id, Sx_id = s[:, 929], s[:, 930]\n",
    "\n",
    "for sim in range(Num_ens):\n",
    "    kd_latent = s[sim, :924]\n",
    "    kd_latent = Tensor(kd_latent.reshape((-1, nf, d, h, w)))\n",
    "    decoder.eval()\n",
    "    log_K = to_numpy(decoder(kd_latent).reshape(-1, 6, 41, 81))[0]\n",
    "    kds.append(log_K)\n",
    "\n",
    "    welspd = []\n",
    "    source_rate = s[sim, 924:929]\n",
    "    for i in range(5):\n",
    "        welspd.append([3, round(Sy_id[sim]), round(Sx_id[sim]), source_rate[i], -1])\n",
    "    welspd.append([3, round(Sy_id[sim]), round(Sx_id[sim]), 0, -1])\n",
    "    con_rate.append(welspd)\n",
    "\n",
    "con_rate = np.array(con_rate)\n",
    "\n",
    "for ndata in range(Num_ens):\n",
    "    hf =  h5py.File('/Volumes/Transcend/Desktop/reactive_inverse/simu_inputs/input_{}.hdf5'.format(ndata), 'w')\n",
    "    hf.create_dataset('kd', data = kds[ndata], dtype ='f', compression = 'gzip')\n",
    "    hf.create_dataset('welspd', data = con_rate[ndata], dtype ='f', compression = 'gzip')\n",
    "    hf.close()\n",
    "## run simulations in parallel\n",
    "cwd = '/Volumes/Transcend/Desktop/reactive_inverse/simu_inputs/'\n",
    "os.chdir(cwd)\n",
    "n_pool = 5\n",
    "pool = Pool(n_pool)\n",
    "filelist = os.listdir(cwd)\n",
    "filelist = [file for file in filelist if file.endswith('.hdf5')]\n",
    "pool.map(simu, filelist)\n",
    "\n",
    "sim_obs = np.zeros((Num_ens,Num_obs))\n",
    "## read output files\n",
    "dir = os.listdir('/Volumes/Transcend/Desktop/reactive_inverse/simu_outputs/')\n",
    "os.chdir('/Volumes/Transcend/Desktop/reactive_inverse/simu_outputs/')\n",
    "sim_obs = np.zeros((Num_ens,Num_obs))\n",
    "\n",
    "for n_data in range(Num_ens):\n",
    "    output_name = 'output_{}.hdf5'.format(n_data)\n",
    "    f = h5py.File(output_name, \"r\")\n",
    "    conc = np.array(f['concentration'])\n",
    "    conc[conc<0] = 0\n",
    "    head = np.array(f['head'])\n",
    "    if len(conc) != 10 or len(head) != 6:\n",
    "        problematic_conc.append([n_data, t])\n",
    "        conc = np.zeros((10,6,41,81))\n",
    "        head = np.zeros((6,41,81))\n",
    "    f.close()\n",
    "    obs = []\n",
    "    obs.append(head[sensor])\n",
    "    for j in range(len(conc)):\n",
    "        obs.append(conc[j][sensor])\n",
    "    obs = np.stack(obs).reshape(-1)\n",
    "\n",
    "    sim_obs[n_data,:] = obs\n",
    "\n",
    "print('RMSE ite_'+str(t)+ ' : ', np.sqrt(np.mean((np.mean(sim_obs,axis=0)-meas_data.flatten())**2))) # not the exact RMSE definition\n",
    "# mean_error[i, t] = np.sqrt(np.mean((np.mean(sim_obs,axis=0)-meas_data.flatten())**2))\n",
    "with open('/Volumes/Transcend/Desktop/reactive_inverse/ESMDA/s_{}.pkl'.format(Na+1),'wb') as file:\n",
    "    pkl.dump([s, sim_obs], file)\n",
    "toc = time.time()\n",
    "total_cpu_time = toc-tic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1028049f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72177.12711000443\n",
      "[[663, 0], [776, 1], [764, 2], [869, 4], [11, 5], [489, 5], [5, 7], [308, 7], [415, 7], [554, 8], [688, 8], [885, 8], [950, 9], [262, 9], [383, 9], [859, 9], [887, 9]]\n"
     ]
    }
   ],
   "source": [
    "print(total_cpu_time)\n",
    "print(problematic_conc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
